
# Masterarbeit â€“ Unsupervised Domain Adaptation zur VerschleiÃŸÃ¼berwachung in Stanzprozessen

Dies ist der Code-Teil meiner Masterarbeit. In dieser Arbeit wird untersucht, wie unÃ¼berwachte Domain-Adaptation-Methoden genutzt werden kÃ¶nnen, um ungelabelte DatensÃ¤tze fÃ¼r die Modellbildung einzusetzen. Ziel ist es, Methoden zu erforschen und zu implementieren, die die Generierung von Pseudo-Labels ermÃ¶glichen, um die DatensÃ¤tze mit kÃ¼nstlichen ZielgrÃ¶ÃŸen fÃ¼r Ã¼berwachtes Lernen nutzbar zu machen.

---

## ğŸ“ Projektstruktur

```
.
â”œâ”€â”€ baseline/
â”‚   â”œâ”€â”€ model/             # Trainings- und Testskripte fÃ¼r Modelle (.py und .ipynb)
â”‚
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ default.yaml             # Konfigurationsdatei fÃ¼r Hyperparameter
â”‚
â”œâ”€â”€ datasets/                    # Datensatzverzeichnis (manuell hinzufÃ¼gen)
â”‚
â”œâ”€â”€ method_pseudo/               # method_pseudo
â”‚   â””â”€â”€ m_pseudo
â”‚ 
â”œâ”€â”€ method_DANN/                # method_DANN
â”‚   â””â”€â”€ m_DANN
â”‚ 
â”œâ”€â”€ models/                      # Modellarchitekturen (z.B. Flexible_CNN)
â”‚
â”œâ”€â”€ preprocessing/               # Datenvorverarbeitung
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ train_utils.py           # Hilfsfunktionen fÃ¼r das Training
â”‚
â”œâ”€â”€ data_preprocessing.py       # Skript zur Erstellung von Datenpfad-Textdateien
â”œâ”€â”€ outliers.py                 # AusreiÃŸerbehandlung
â”œâ”€â”€ requirements.txt            # AbhÃ¤ngigkeiten fÃ¼r Python
â”œâ”€â”€ Denken und Reflexion.md     # Denken und Reflexion
â””â”€â”€ README.md                   # Diese Dokumentation
```

---

## Schnellstart

### 1. AbhÃ¤ngigkeiten installieren

Virtuelle Umgebung empfohlen:

```bash
pip install -r requirements.txt
```

---

### 2. Daten vorbereiten

Nutze `data_preprocessing.py`, um Datenpfade aus `datasets` nach `datasets/source/` zu generieren:

- Trainingsdaten: `train/DC_T197_RP.txt`
- Validierungsdaten: `validation/HC_T197_RP.txt`
- Testdaten: `test/DC_T197_RP.txt` (fÃ¼r `baseline_test`)

---

### 3. Modellbau

AusfÃ¼hren:

```bash
models/Flexible_CNN.py	
models/Flexible_DANN.py	
models/generate_pseudo_labels.py	
models/get_no_label_dataloader.py	
```

- Verwenden Sie Flexible_CNN.py, um einen grundlegenden CNN-Klassifikator zu erstellen.
-  Verwenden Sie Flexible_DANN.py, um ein DomÃ¤nenanpassungsmodell zu erstellen.
-  Laden Sie den unbeschrifteten Datensatz Ã¼ber get_no_label_dataloader.py 
- Und generieren Sie schlieÃŸlich Pseudo-Labels mit generate_pseudo_labels.py

---

### 4. Modelltraining und Test

AusfÃ¼hren:

```bash
python baseline/baseline.py	
python baseline/baseline_test.py	
```

- Funktionen:
  - Liest Konfiguration aus `configs/default.yaml`
  - Trainiert das Flexible_CNN-Modell
  - Speichert das beste Modell nach `model/best_model.pth`
  - Test 

---

### 5. Domain Adaptation Training (In Arbeit)

Method pseudo:

```bash
method_pseudo/m_pseudo.py
method_pseudo/iterative_pseudo_labeling.py
```

Ausgabe:

- Source Accuracy:
- Test Accuracy:
- Performanceverbesserung:

Method DANN:

```bash
method_DANN/m_DANN.py
method_DANN/m_DANN.ipynb
```

Ausgabe:
- Source Accuracy:0.3996
- Test Accuracy:0.6826
- Performanceverbesserung:0.283





---

## Konfigurationsdatei (configs/default.yaml)

```yaml
baseline:
  batch_size: 16
  learning_rate: 0.0001694841438362755
  weight_decay: 0.0006531754995659995
  num_layers: 6
  kernel_size: 15
  start_channels: 8
  num_epochs: 30
  early_stopping_patience: 5
```

---

## Modellarchitektur

- Modell befindet sich in `models`
- Parameter anpassbar: Anzahl der Convolution-Layers, StartkanÃ¤le, KernelgrÃ¶ÃŸe, Aktivierungsfunktionen

---

## TODO

- [ ] Vergleich mehrerer Modelle
- [ ] TensorBoard-Integration
- [ ] Confusion Matrix-Ausgabe
- [ ] Flexible Daten-Typumwandlung


