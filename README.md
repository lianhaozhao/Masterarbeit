
# Masterarbeit â€“ Unsupervised Domain Adaptation zur VerschleiÃŸÃ¼berwachung in Stanzprozessen

Dies ist der Code-Teil meiner Masterarbeit. In dieser Arbeit wird untersucht, wie unÃ¼berwachte Domain-Adaptation-Methoden genutzt werden kÃ¶nnen, um ungelabelte DatensÃ¤tze fÃ¼r die Modellbildung einzusetzen. Ziel ist es, Methoden zu erforschen und zu implementieren, die die Generierung von Pseudo-Labels ermÃ¶glichen, um die DatensÃ¤tze mit kÃ¼nstlichen ZielgrÃ¶ÃŸen fÃ¼r Ã¼berwachtes Lernen nutzbar zu machen.

---

## ğŸ“ Projektstruktur

```
.
â”œâ”€â”€ baseline/
â”‚   â”œâ”€â”€ model/             # Trainings- und Testskripte fÃ¼r Modelle (.py und .ipynb)
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ default.yaml             # Konfigurationsdatei fÃ¼r Hyperparameter
â”‚
â”œâ”€â”€ datasets/                    # Datensatzverzeichnis (manuell hinzufÃ¼gen)
â”‚
â”œâ”€â”€ models/                      # Modellarchitekturen (z.B. Flexible_CNN)
â”‚
â”œâ”€â”€ preprocessing/               # Datenvorverarbeitung
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ train_utils.py           # Hilfsfunktionen fÃ¼r das Training
â”‚
â”œâ”€â”€ data_preprocessing.py       # Skript zur Erstellung von Datenpfad-Textdateien
â”œâ”€â”€ outliers.py                 # AusreiÃŸerbehandlung
â”œâ”€â”€ requirements.txt            # AbhÃ¤ngigkeiten fÃ¼r Python
â””â”€â”€ README.md                   # Diese Dokumentation
```

---

## ğŸš€ Schnellstart

### 1. AbhÃ¤ngigkeiten installieren

Virtuelle Umgebung empfohlen:

```bash
pip install -r requirements.txt
```

---

### 2. Daten vorbereiten

Nutze `data_preprocessing.py`, um Datenpfade aus `datasets` nach `datasets/source/` zu generieren:

- Trainingsdaten: `train/DC_T197_RP.txt`
- Validierungsdaten: `validation/HC_T197_RP.txt`
- Testdaten: `test/DC_T197_RP.txt` (fÃ¼r `baseline_test`)

---

### 3. Modelltraining

AusfÃ¼hren:

```bash
python baseline/baseline.py
```

Funktionen:
- Liest Konfiguration aus `configs/default.yaml`
- Trainiert das Flexible_CNN-Modell
- Speichert das beste Modell nach `model/best_model.pth`

---

### 4. Modelltest

AusfÃ¼hren:

```bash
python baseline/baseline_test.py
```

Ausgabe:
- Test Loss
- Test Accuracy

---

### 5. Domain Adaptation Training (in Arbeit)

AusfÃ¼hren:

```bash
# wird noch ergÃ¤nzt
```

Ausgabe:
- Test Loss
- Test Accuracy
- Performanceverbesserung

---

## ğŸ”§ Konfigurationsdatei (configs/default.yaml)

```yaml
baseline:
  batch_size: 64
  learning_rate: 0.001
  weight_decay: 0.0001
  num_layers: 3
  kernel_size: 3
  start_channels: 32
  num_epochs: 30
  early_stopping_patience: 5
```

---

## ğŸ“¦ Modellarchitektur

- Modell befindet sich in `models`
- Parameter anpassbar: Anzahl der Convolution-Layers, StartkanÃ¤le, KernelgrÃ¶ÃŸe, Aktivierungsfunktionen

---

## âœ… TODO

- [ ] Vergleich mehrerer Modelle
- [ ] TensorBoard-Integration
- [ ] Confusion Matrix-Ausgabe
- [ ] Flexible Daten-Typumwandlung


